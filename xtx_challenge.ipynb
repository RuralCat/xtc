{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "data = pd.read_csv(\"data-training.csv\")\n",
    "data_array = np.array(data)\n",
    "\n",
    "# show sample\n",
    "print(data[0:2])\n",
    "\n",
    "# plot distribution\n",
    "sns.distplot(data_array[:, 60], kde=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = data.dropna(axis=0)\n",
    "new_data = new_data.drop_duplicates()\n",
    "print('data size:', new_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split to train & test\n",
    "train_data  = new_data[0:2000000]\n",
    "test_data = new_data[2000000:2700000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_1st = data['askRate0'] - data['bidRate0']\n",
    "diff_2nd = np.diff(diff_1st)\n",
    "plt.scatter(diff_2nd, np.diff(data['y']))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_data[train_data.columns[0:60]])\n",
    "train_y = np.array(train_data['y'])\n",
    "test_x = np.array(test_data[test_data.columns[0:60]])\n",
    "test_y = np.array(test_data['y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('normed_data.pickle', 'rb') as f:\n",
    "    normed_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### askrate0 diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_diff = np.zeros((data_array.shape[0], 30), dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag1 = np.all(data_array[:-1, 30:60] == data_array[1:, 30:60], axis=1)\n",
    "\n",
    "flag2 = np.all(data_array[:-1, 1:15] == data_array[1:, 0:14], axis=1)\n",
    "flag2_ = np.all(data_array[:-1, 16:30] == data_array[1:, 15:29], axis=1)\n",
    "\n",
    "flag3 = np.all(data_array[:-1, 0:14] == data_array[1:, 1:15], axis=1)\n",
    "flag3_ = np.all(data_array[:-1, 15:29] == data_array[1:, 16:30], axis=1)\n",
    "\n",
    "flag = flag1 & ((flag2 & flag2_) | (flag3 & flag3_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = data.shape[0] - 1\n",
    "data_t1 = np.array(data.loc[np.arange(nb)[flag]+1])\n",
    "data_t0 = np.array(data.loc[np.arange(nb)[flag]])\n",
    "diff_ask = (data_t1[:, 0] - data_t0[:, 0]) #/ (data_t0[:, 0] - data_t0[:, 30])\n",
    "diff_ask_bid = data_t0[:, 0] - data_t0[:, 30]\n",
    "diff_y = data_t1[:, -1] - data_t0[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diff_ask_bid[diff_ask==0.5], diff_y[diff_ask==0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(diff_ask, diff_y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(diff_ask, diff_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data_array = np.nan_to_num(data_array, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "normed_data = np.zeros_like(data_array, dtype=np.float32)\n",
    "normed_data[:, :15] = data_array[:, :15] - np.expand_dims(data_array[:, 0], axis=1)\n",
    "normed_data[:, 30:45] = data_array[:, 30:45] - np.expand_dims(data_array[:, 0], axis=1)\n",
    "\n",
    "asksize_book = {x:0 for x in np.arange(1500, 1800, 0.5)}\n",
    "bidsize_book = {x:0 for x in np.arange(1500, 1800, 0.5)}\n",
    "\n",
    "temp_asksize_book = {}\n",
    "temp_bidsize_book = {}\n",
    "for i in range(data_array.shape[0]):\n",
    "    for j in range(15):\n",
    "        # for ask\n",
    "        if data_array[i, j] not in temp_asksize_book and j < 12:\n",
    "            normed_data[i, j+15] = data_array[i ,j+15]\n",
    "        else:\n",
    "            normed_data[i, j+15] = data_array[i, j+15] - asksize_book[data_array[i, j]]\n",
    "        # update ask size book\n",
    "        asksize_book[data_array[i, j]] = data_array[i, j+15]\n",
    "    \n",
    "    for j in range(30, 45):\n",
    "        # for bid\n",
    "        if data_array[i, j] not in temp_bidsize_book and j < 42:\n",
    "            normed_data[i, j+15] = data_array[i ,j+15]\n",
    "        else:\n",
    "            normed_data[i, j+15] = data_array[i, j+15] - bidsize_book[data_array[i, j]]\n",
    "        # update bid size book\n",
    "        bidsize_book[data_array[i, j]] = data_array[i, j+15]\n",
    "        \n",
    "    # update temp book\n",
    "    temp_asksize_book = {data_array[i,k]: data_array[i,k+15] for k in range(15)}\n",
    "    temp_bidsize_book = {data_array[i,k+30]: data_array[i,k+45] for k in range(15)}\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_data[normed_data < -1000] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = 2000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = data_array[:nb_train, 0:60]# - data_array[:nb_train, 30:60]\n",
    "train_y = data_array[:nb_train, 60]\n",
    "\n",
    "x1 = data_array[nb_train:, 0:60]# - data_array[nb_train:, 30:60]\n",
    "test_y = data_array[nb_train:, 60]\n",
    "\n",
    "reg = LinearRegression(normalize=True).fit(x0, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = reg.predict(x0)\n",
    "test_pred = reg.predict(x1)\n",
    "\n",
    "\n",
    "print('train score: {:.5f}'.format(score(train_y, train_pred)))\n",
    "print('test score: {:.5f}'.format(score(test_y, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear model with normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('normed_data.pickle', 'rb') as f:\n",
    "    normed_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = 2000000\n",
    "# train data\n",
    "train_x = normed_data[:nb_train, :60]\n",
    "train_y = normed_data[:nb_train, 60]\n",
    "# test data\n",
    "test_x = normed_data[nb_train:, :60]\n",
    "test_y = normed_data[nb_train:, 60]\n",
    "\n",
    "reg = LinearRegression(normalize=False).fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = reg.predict(train_x)\n",
    "test_pred = reg.predict(test_x)\n",
    "\n",
    "\n",
    "print('train score: {:.5f}'.format(score(train_y, train_pred)))\n",
    "print('test score: {:.5f}'.format(score(test_y, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear model with multi - normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tile(x, n):\n",
    "    res = np.zeros((x.shape[0] - n + 1, x.shape[1], n), dtype=np.float32)\n",
    "    for i in range(n):\n",
    "        if i > 0:\n",
    "            res[..., i] = x[n-i-1 : -i]\n",
    "        else:\n",
    "            res[..., 0] = x[n-1:]\n",
    "    return res.reshape((res.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 8\n",
    "# train data\n",
    "train_x = tile(normed_data[:nb_train, :60], n)\n",
    "train_y = data_array[n-1:nb_train, 60]\n",
    "# test data\n",
    "test_x = tile(normed_data[nb_train:, :60], n)\n",
    "test_y = data_array[nb_train+n-1:, 60]\n",
    "\n",
    "reg = LinearRegression(normalize=False).fit(train_x.reshape(train_x.shape[0], -1), train_y)\n",
    "\n",
    "# test\n",
    "train_pred = reg.predict(train_x.reshape(train_x.shape[0], -1))\n",
    "test_pred = reg.predict(test_x.reshape(test_x.shape[0], -1))\n",
    "\n",
    "\n",
    "print('train score: {:.5f}'.format(score(train_y, train_pred)))\n",
    "print('test score: {:.5f}'.format(score(test_y, test_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear model with pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "pca = pca.fit(train_x)\n",
    "\n",
    "x0 = pca.transform(train_x)\n",
    "x1 = pca.transform(test_x)\n",
    "\n",
    "reg = LinearRegression().fit(x0, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = reg.predict(x0)\n",
    "test_pred = reg.predict(x1)\n",
    "\n",
    "print('train score: {:.5f}'.format(score(train_y, train_pred)))\n",
    "print('test score: {:.5f}'.format(score(test_y, test_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "stem_cell": {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
